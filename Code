Linear Least Squares Prediction (LLP5)
Mathematical Logic: Linear regression minimizes the sum of the squared differences between observed values and predicted values (least squares method).
Formula:
𝑦
=
𝛽
0
+
𝛽
1
𝑥
y=β 
0
​
 +β 
1
​
 x

where 
𝑦
y is the predicted value, 
𝛽
0
β 
0
​
  is the intercept, 
𝛽
1
β 
1
​
  is the slope, and 
𝑥
x is the independent variable (time in most cases).
Linear Least Squares Trend (LLT2)
Mathematical Logic: Similar to LLP5, this algorithm focuses on fitting a linear trend to the data over time.
Formula:
𝑦
=
𝛽
0
+
𝛽
1
𝑥
+
𝜖
y=β 
0
​
 +β 
1
​
 x+ϵ

where 
𝜖
ϵ represents the error term.
Linear Least Squares Trend with Seasonality (LLT3)
Mathematical Logic: Combines linear regression with seasonal decomposition. It accounts for both linear trends and repeating seasonal patterns.
Formula:
𝑦
=
𝛽
0
+
𝛽
1
𝑥
+
𝑆
𝑡
+
𝜖
y=β 
0
​
 +β 
1
​
 x+S 
t
​
 +ϵ

where 
𝑆
𝑡
S 
t
​
  represents the seasonal component.
4. Access the Source Code
If you need the exact implementation details, you may need access to the source code or detailed algorithm documentation. Splunk Enterprise customers might have access to more in-depth resources through support or engineering contacts.

5. Utilize External Resources
For a deeper understanding, consult textbooks or online resources on time-series analysis and the specific algorithms:

Linear Regression: “Introduction to Statistical Learning” by James et al.
Time-Series Analysis: “Time Series Analysis and Its Applications” by Shumway and Stoffer.
6. Example Calculation
To see how it works, manually apply the algorithm on a small dataset:

Example Dataset
Time	Value
1	2
2	3
3	5
4	4
5	6
Linear Regression Calculation
Calculate the mean of 
𝑥
x (time) and 
𝑦
y (value).

Compute the slope (
𝛽
1
β 
1
​
 ) and intercept (
𝛽
0
β 
0
​
 ) using the formulas:

𝛽
1
=
∑
(
𝑥
𝑖
−
𝑥
ˉ
)
(
𝑦
𝑖
−
𝑦
ˉ
)
∑
(
𝑥
𝑖
−
𝑥
ˉ
)
2
β 
1
​
 = 
∑(x 
i
​
 − 
x
ˉ
 ) 
2
 
∑(x 
i
​
 − 
x
ˉ
 )(y 
i
​
 − 
y
ˉ
​
 )
​
 

𝛽
0
=
𝑦
ˉ
−
𝛽
1
𝑥
ˉ
β 
0
​
 = 
y
ˉ
​
 −β 
1
​
  
x
ˉ
